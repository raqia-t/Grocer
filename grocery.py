# -*- coding: utf-8 -*-
"""Grocery

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1_Ig_q1zLOKmzUQE9v_VvfWc3vnl0mjz0

#Set Up Dependencies
"""

!pip install ultralytics

from google.colab import drive
drive.mount('/content/drive')

"""#Fine Tune Yolov8 on custom data"""

import os
from ultralytics import YOLO
# import torch
# import torch_xla
# import torch_xla.core.xla_model as xm

"""
Example script to fine-tune a YOLOv8 model on a custom dataset
and run inference. Adjust parameters as needed.
"""

# -------------------------------------------------------
# 1. Load a Pretrained YOLOv8 Model
# -------------------------------------------------------
model = YOLO('yolov8n.pt')  # or path to your custom checkpoint (using nano i.e. smallest)

# -------------------------------------------------------
# 2. Train (Fine-Tune) on Custom Dataset
# -------------------------------------------------------
# data.yaml must have the structure:
# train: path/to/train/
# val:   path/to/val/
# test:  path/to/test/
# nc: <number_of_classes>
# names: [<class1>, <class2>, ...]
# For above the path will be from drive mounted, hence better to create a folder and add data into that folder
#
#
# Example parameters:
#  - epochs: how many times to loop over your training data
#  - imgsz: image size for training
#  - batch: batch size
#  - device: 'cpu' or e.g. '0' for GPU #0
#  - pretrained: True means starting from pretrained weights
#  - other hyperparameters: see Ultralytics YOLO docs
#

data_config = '/content/drive/MyDrive/Data/grocery_yolov8/grocery_yolov8/data.yaml'

results = model.train(
    data=data_config,
    epochs=57,
    imgsz=640,
    batch=8,
    device=0,  # or some other numerical, like 0 (this would normally use all gpu's available), or 1 , or '0,1'
    # device = xm.xla_device(), # For TPU not working
    workers=4  # number of dataloader workers
)

# -------------------------------------------------------
# 3. Validate the Model on the Validation Set
# -------------------------------------------------------
# This will give metrics like mAP, precision, recall, etc.
val_results = model.val()
print("Validation results:", val_results)

"""#Test the fine tuned model"""

#Load the best model (best.pt)
model = YOLO('/content/runs/detect/train2/weights/best.pt')

# -------------------------------------------------------
# 4. Run Inference (Prediction) on New Images
# -------------------------------------------------------
# You can pass a single image path or a folder containing images.
# The model will output predictions (bounding boxes, confidence).

# infer_images_path = '/content/drive/MyDrive/Data/grocery_yolov8/test/images/'

infer = '/content/drive/MyDrive/Data/grocery_yolov8/grocery_yolov8/test/images/20241205_141507_jpg.rf.c9440386a929ffddfa5f5f486122eecb.jpg'

inference_results = model.predict(source=infer,  # or a single image 'test/image.jpg'
                                      conf=0.8,        # confidence threshold
                                      iou=0.6,         # IoU threshold
                                      save=True,        # save predictions as images
                                      project='inference_results',  # where to save
                                      name='detected')       # subfolder name
print("Inference completed.")

"""#Run inference (input set as infer.mp4), and output the video"""

import cv2
from ultralytics import YOLO
import os

def main():
    # ----------------------------
    # 1. Load the Finetuned Model
    # ----------------------------
    # Replace with the path to your best.pt file
    model_path = '/content/runs/detect/train2/weights/best.pt'
    model = YOLO(model_path)

    # model.names = {
    #    0: "soap",
    #    1: "ketchup",
    #    2: "masala"
    # }

    # Adjust costs here if needed
    item_costs = {
        "soap": 70,
        "ketchup": 250,
        "masala": 100
    }

    # ----------------------------
    # 2. Define Counting Structures
    # ----------------------------
    # We want to count items only once for each unique tracked object.
    # So for each class, we maintain a set of unique track IDs we've seen.
    seen_ids_per_class = {name: set() for name in item_costs.keys()}

    # This dictionary will store the final count of each item
    item_counts = {name: 0 for name in item_costs.keys()}

    # ------------------------------------
    # 3. Open the Video and Prepare Writer
    # ------------------------------------
    input_video = 'soap_infer.mp4'
    output_video = 'output_infer.mp4'  # Output filename

    cap = cv2.VideoCapture(input_video)
    if not cap.isOpened():
        print(f"Error: Could not open video {input_video}")
        return

    # Get video properties
    width  = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    fps    = cap.get(cv2.CAP_PROP_FPS)

    # Define VideoWriter to save annotated video
    fourcc = cv2.VideoWriter_fourcc(*'mp4v')
    out = cv2.VideoWriter(output_video, fourcc, fps, (width, height))

    # -----------------------------
    # 4. Process Video Frame by Frame
    # -----------------------------
    while True:
        ret, frame = cap.read()
        if not ret:
            break

        # Track objects in the current frame
        # We use 'stream=True' to get generator results we can iterate over
        # in real-time. Alternatively, you can call once with an image, but
        # using track() is recommended for multi-object tracking.
        results = model.track(frame, stream=True, imgsz=640, conf=0.5, iou=0.5, device='cpu')

        # results is a generator; we iterate to get each result
        # Usually for a single image, there's only one result in the generator
        for result in results:
            # result.boxes contains detections (xyxy, confidence, class, etc.)
            # result.boxes.id is the unique track ID assigned if 'track=True'
            annotated_frame = result.plot()  # annotated_frame is a NumPy array with bounding boxes, etc.

            # Iterate over the detections in this result
            if result.boxes is not None:
                for box in result.boxes:
                    cls_id = int(box.cls[0])  # class index (e.g., 0,1,2,...)
                    track_id = int(box.id[0]) if box.id is not None else None

                    # Convert cls_id to class name
                    class_name = model.names[cls_id]

                    # Only update the count for classes we have in item_costs
                    if class_name in item_costs:
                        # Add the track_id to the set if not already present
                        if track_id is not None and track_id not in seen_ids_per_class[class_name]:
                            seen_ids_per_class[class_name].add(track_id)
                            item_counts[class_name] += 1

            # --------------------------------------
            # 5. Overlay Counts and Total Cost on Frame
            # --------------------------------------
            # Calculate the total cost so far
            total_cost = 0
            for name, count in item_counts.items():
                total_cost += item_costs[name] * count

            # Let's put the item counts in the top-left corner
            y_offset = 30
            for name, count in item_counts.items():
                text = f"{name}: {count}"
                cv2.putText(
                    annotated_frame, text, (10, y_offset),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 0), 2
                )
                y_offset += 30

            # Put total cost below the item counts
            cv2.putText(
                annotated_frame,
                f"Total Cost: {total_cost}",
                (10, y_offset),
                cv2.FONT_HERSHEY_SIMPLEX,
                0.8,
                (0, 255, 255),
                2
            )

            # Write annotated frame to output video
            out.write(annotated_frame)

    # ---------------------
    # 6. Release Resources
    # ---------------------
    cap.release()
    out.release()
    cv2.destroyAllWindows()

    # Print final counts and total cost
    print("Final Counts:", item_counts)
    total_cost = sum(item_costs[k] * v for k, v in item_counts.items())
    print("Total Cost:", total_cost)

if __name__ == "__main__":
    main()